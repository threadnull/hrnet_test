{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e2df2",
   "metadata": {
    "executionInfo": {
     "elapsed": 24790,
     "status": "ok",
     "timestamp": 1769583637097,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "2a8e2df2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import kornia\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1k4ivpMIJlpi",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1769583641094,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "1k4ivpMIJlpi"
   },
   "outputs": [],
   "source": [
    "# imagenet 평균, 표준편차\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "# SIGMA\n",
    "SIGMA = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a293b8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1769583639045,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "a5a293b8"
   },
   "outputs": [],
   "source": [
    "# 모델\n",
    "class GaugeHRNet(nn.Module):\n",
    "    def __init__(self, num_keypoints=4, pretrained=True, stride_idx=1):\n",
    "        super(GaugeHRNet, self).__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            \"hrnet_w18\",\n",
    "            pretrained=pretrained,\n",
    "            features_only=True\n",
    "        )\n",
    "        self.stride_idx = stride_idx\n",
    "        # Stride 4 (64x64) 특징맵 채널 수 가져오기\n",
    "        in_channels = self.backbone.feature_info.channels()[self.stride_idx]\n",
    "\n",
    "        self.final_layer = nn.Conv2d(in_channels, num_keypoints, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 특징맵 리스트 추출\n",
    "        x = self.backbone(x)[self.stride_idx]\n",
    "        # Stride 4 (64x64)\n",
    "        x = self.final_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dc2cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1769583642315,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "3f4dc2cf"
   },
   "outputs": [],
   "source": [
    "# 데이터셋\n",
    "class GaugeDataset(Dataset):\n",
    "    def __init__(self, root_dir, ann_file, input_size=(256, 256), is_train=True):\n",
    "        self.root_dir = root_dir\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            self.coco = json.load(f)\n",
    "        self.image_map = {img[\"id\"]: img for img in self.coco[\"images\"]}\n",
    "        self.annotaions = self.coco[\"annotations\"]\n",
    "        self.input_size = input_size\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # 정규화\n",
    "        self.normalize = T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "\n",
    "        # 증강\n",
    "        self.augment = T.Compose([\n",
    "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
    "        ]) if is_train else nn.Identity()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotaions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        annotaion = self.annotaions[index]\n",
    "        image_info = self.image_map[annotaion[\"image_id\"]]\n",
    "        image_path = os.path.join(self.root_dir, image_info[\"file_name\"])\n",
    "\n",
    "        # Tensor C H W, 리사이즈, 0~255\n",
    "        image = read_image(image_path)\n",
    "        image = F.resize(image, self.input_size)\n",
    "        image = image.float() / 255.0\n",
    "\n",
    "        # 증강\n",
    "        image = self.augment(image)\n",
    "        # 정규화\n",
    "        image = self.normalize(image)\n",
    "        \n",
    "        # 좌표 스케일링\n",
    "        # 원본 이미지 크기 정보 가져오기\n",
    "        w = image_info['width']\n",
    "        h = image_info['height']\n",
    "\n",
    "        scale_x = self.input_size[1] / w\n",
    "        scale_y = self.input_size[0] / h\n",
    "\n",
    "        keypoints = torch.tensor(annotaion[\"keypoints\"]).view(-1, 3).float()\n",
    "        keypoints[:, 0] *= scale_x\n",
    "        keypoints[:, 1] *= scale_y\n",
    "\n",
    "        return image, keypoints[:, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ba592",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1769583646315,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "815ba592"
   },
   "outputs": [],
   "source": [
    "# 히트맵\n",
    "def generate_heatmap(keypoints, map_size, sigma=SIGMA):\n",
    "    \"\"\"\n",
    "    [학습용] 좌표 -> 히트맵\n",
    "    \"\"\"\n",
    "    B, N, _ = keypoints.shape\n",
    "    H, W = map_size\n",
    "    device = keypoints.device\n",
    "\n",
    "    # 표준편차\n",
    "    std = torch.tensor([sigma, sigma], device=device).repeat(B, N, 1)\n",
    "\n",
    "    # Kornia 히트맵 렌더링\n",
    "    heatmaps = kornia.geometry.subpix.render_gaussian2d(\n",
    "        mean=keypoints,\n",
    "        std=std,\n",
    "        size=(H, W),\n",
    "        normalized_coordinates=False # 픽셀 좌표계 사용\n",
    "    )\n",
    "    return heatmaps\n",
    "\n",
    "def decode_heatmap(heatmaps):\n",
    "    \"\"\"\n",
    "    [추론용] 히트맵 -> 좌표\n",
    "    \"\"\"\n",
    "    # Soft Argmax\n",
    "    # temperature가 높을수록 argmax에 가까워지고, 낮을수록 평균에 가까워짐\n",
    "    coords = kornia.geometry.subpix.spatial_soft_argmax2d(\n",
    "        input=heatmaps,\n",
    "        temperature=torch.tensor(1.0, device=heatmaps.device),\n",
    "        normalized_coordinates=False\n",
    "    )\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atRHLTO9KIne",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1769583644449,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "atRHLTO9KIne"
   },
   "outputs": [],
   "source": [
    "# 히트맵 확인\n",
    "def check_heatmap(dataset):\n",
    "    # 데이터 하나 샘플링\n",
    "    image, keypoints = dataset[0]\n",
    "\n",
    "    # 256 -> 64 스케일\n",
    "    kps = keypoints.unsqueeze(0) / 4.0\n",
    "\n",
    "    # 히트맵 생성\n",
    "    targets = generate_heatmap(kps, (64, 64), sigma=SIGMA)\n",
    "\n",
    "    # 시각화\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # 정답 히트맵\n",
    "    heatmap_vis = targets[0].sum(dim=0).cpu().numpy()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(heatmap_vis, cmap='jet')\n",
    "    plt.title(\"Target Heatmap (Ground Truth)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 좌표 위치\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # 이미지 역정규화\n",
    "    inv_mean = torch.tensor([-m/s for m, s in zip(IMAGENET_MEAN, IMAGENET_STD)]).view(3, 1, 1)\n",
    "    inv_std = torch.tensor([1/s for s in IMAGENET_STD]).view(3, 1, 1)\n",
    "    img_vis = image * inv_std + inv_mean\n",
    "    img_vis = img_vis.permute(1, 2, 0).numpy()\n",
    "    img_vis = np.clip(img_vis, 0, 1)\n",
    "\n",
    "    plt.imshow(img_vis)\n",
    "\n",
    "    kps_np = keypoints.numpy()\n",
    "\n",
    "    plt.scatter(kps_np[:, 0], kps_np[:, 1], c='red', s=50)\n",
    "    plt.title(\"\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5378dd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1769583997719,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "b5378dd5"
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, keypoints in tqdm(dataloader, desc=\"학습중 \"):\n",
    "        images = images.to(device)\n",
    "        keypoints = keypoints.to(device)\n",
    "\n",
    "        # hrnet target 1/4\n",
    "        with torch.no_grad():\n",
    "            target_keypoints = keypoints / 4.0\n",
    "            targets = generate_heatmap(target_keypoints, (64, 64), sigma=SIGMA)\n",
    "\n",
    "            targets = targets * 1000.0\n",
    "\n",
    "        # 전파\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# 검증\n",
    "def val(model, dataloader, criterion, device, epoch_idx=0):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for i, (images, keypoints) in tqdm(enumerate(dataloader), \"검증중 \"):\n",
    "        images = images.to(device)\n",
    "        keypoints = keypoints.to(device)\n",
    "\n",
    "        target_keypoints = keypoints / 4.0\n",
    "        targets = generate_heatmap(target_keypoints, (64, 64), sigma=SIGMA)\n",
    "\n",
    "        # [중요] 학습 때와 동일하게 스케일링 적용해야 Loss 비교 가능\n",
    "        targets = targets * 1000.0\n",
    "\n",
    "        # 전파\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 첫 번째 배치의 결과만 출력 확인\n",
    "        if i == 0:\n",
    "            # 좌표 복원 시에는 Scaling된 히트맵도 위치는 동일하므로 그대로 사용 가능\n",
    "            pred_coords = decode_heatmap(outputs)\n",
    "            pred_coords = pred_coords * 4.0\n",
    "                \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bf465",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1769583650514,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "6c1bf465"
   },
   "outputs": [],
   "source": [
    "# 설정\n",
    "TRAIN_IMG = \"coco_dataset/train/images\"\n",
    "TRAIN_ANN = \"coco_dataset/train/labels/person_keypoints_Train.json\"\n",
    "VAL_IMG = \"coco_dataset/val/images\"\n",
    "VAL_ANN = \"coco_dataset/val/labels/person_keypoints_Validation.json\"\n",
    "SAVE_PATH = \"models/hrnet/hrnet.pth\"\n",
    "NUM_KEYPOINTS = 4\n",
    "BATCH_SIZE = 16\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc71118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cyHwu_obKRwL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 2619,
     "status": "ok",
     "timestamp": 1769583654051,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "cyHwu_obKRwL",
    "outputId": "d2cbf6c9-def1-4b02-96f9-ae869f043374"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_ANN) and os.path.exists(TRAIN_IMG):\n",
    "    test_dataset = GaugeDataset(TRAIN_IMG, TRAIN_ANN)\n",
    "    check_heatmap(test_dataset)\n",
    "else:\n",
    "    print(\"데이터셋 경로를 확인하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3xyQsUen91ye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3885524,
     "status": "ok",
     "timestamp": 1769587886456,
     "user": {
      "displayName": "Threadnull",
      "userId": "07662794831980327292"
     },
     "user_tz": -540
    },
    "id": "3xyQsUen91ye",
    "outputId": "334e9f27-5f2d-40ed-e69a-45cbff4142d6"
   },
   "outputs": [],
   "source": [
    "# 모델\n",
    "model = GaugeHRNet(num_keypoints=NUM_KEYPOINTS).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94201fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 로드\n",
    "if os.path.exists(TRAIN_ANN) and os.path.exists(VAL_ANN):\n",
    "    train_dataset = GaugeDataset(TRAIN_IMG, TRAIN_ANN, is_train=True)\n",
    "    val_dataset = GaugeDataset(VAL_IMG, VAL_ANN, is_train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5)\n",
    "\n",
    "    print(f\"학습 시작 (Device: {DEVICE})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        val_loss = val(model, val_loader, criterion, DEVICE)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{EPOCH} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # 성능 개선 시 모델 저장\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), SAVE_PATH)\n",
    "            print(f\"모델 저장: {val_loss:.6f}\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "    print(\"학습 완료 및 모델 저장됨.\")\n",
    "\n",
    "else:\n",
    "    print(\"데이터셋 파일이 없습니다. 경로를 확인해주세요.\")\n",
    "\n",
    "    # dummy tets\n",
    "    print(\"\\nKornia 기능 테스트\")\n",
    "    dummy_out = torch.randn(1, 2, 64, 64).to(DEVICE)\n",
    "    coords = decode_heatmap(dummy_out)\n",
    "    print(f\"Soft-Argmax 결과): {coords[0,0].tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
