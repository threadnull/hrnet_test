{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a84b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arkplus\\anaconda3\\envs\\hrnet\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from util import decode_heatmap\n",
    "from model import GaugeHRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903cfa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "NUM_KEYPOINTS = 4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# KEYPOINTS = [\"center\", \"tip\", \"min\", \"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db437ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, frame_np, device, input_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    frame_np: OpenCV로 읽은 BGR 이미지 (Numpy array)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # 원본 크기\n",
    "    h, w = frame_np.shape[:2]\n",
    "\n",
    "    # BGR -> RGB\n",
    "    frame_rgb = cv2.cvtColor(frame_np, cv2.COLOR_BGR2RGB)\n",
    "    # nparray -> tensor\n",
    "    frame_tensor = F.to_tensor(frame_rgb)\n",
    "    # 정규화\n",
    "    frame_tensor = T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)(frame_tensor)\n",
    "    # 리사이즈\n",
    "    frame_input = F.resize(frame_tensor, input_size)\n",
    "    # 배치차원추가 [C, H, W] -> [1, C, H, W]\n",
    "    frame_input = frame_input.unsqueeze(0).to(device)\n",
    "\n",
    "    # 추론\n",
    "    with torch.no_grad():\n",
    "        outputs = model(frame_input)\n",
    "        \n",
    "        # Heatmap -> 좌표 변환 (64x64 기준 좌표)\n",
    "        pred_coords = decode_heatmap(outputs)  # [1, K, 2]\n",
    "\n",
    "    # 64x64 -> 256x256\n",
    "    pred_coords = pred_coords * 4.0\n",
    "    \n",
    "    # 256x256 기준 좌표를 원본 이미지 크기로 다시 변환\n",
    "    scale_x = w / input_size[1]\n",
    "    scale_y = h / input_size[0]\n",
    "    \n",
    "    pred_coords[0, :, 0] *= scale_x\n",
    "    pred_coords[0, :, 1] *= scale_y\n",
    "\n",
    "    # 좌표반환\n",
    "    return pred_coords[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ab5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (downsamp_modules.0.1.num_batches_tracked, downsamp_modules.1.1.num_batches_tracked, downsamp_modules.2.1.num_batches_tracked, final_layer.1.num_batches_tracked, downsamp_modules.0.0.bias, downsamp_modules.0.0.weight, downsamp_modules.0.1.bias, downsamp_modules.0.1.running_mean, downsamp_modules.0.1.running_var, downsamp_modules.0.1.weight, downsamp_modules.1.0.bias, downsamp_modules.1.0.weight, downsamp_modules.1.1.bias, downsamp_modules.1.1.running_mean, downsamp_modules.1.1.running_var, downsamp_modules.1.1.weight, downsamp_modules.2.0.bias, downsamp_modules.2.0.weight, downsamp_modules.2.1.bias, downsamp_modules.2.1.running_mean, downsamp_modules.2.1.running_var, downsamp_modules.2.1.weight, final_layer.0.bias, final_layer.0.weight, final_layer.1.bias, final_layer.1.running_mean, final_layer.1.running_var, final_layer.1.weight, classifier.bias, classifier.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrnet.pth 모델 불러오기 완료\n",
      "640 x 240 MJPG\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        checkpoint = \"models/hrnet/hrnet.pth\"\n",
    "        state_dict = torch.load(checkpoint, map_location=DEVICE)\n",
    "        model = GaugeHRNet(num_keypoints=NUM_KEYPOINTS).to(DEVICE)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"{os.path.basename(checkpoint)} 모델 불러오기 완료\")\n",
    "\n",
    "    except:\n",
    "        print(\"Error: 모델 불러오기 실패\")\n",
    "        exit()\n",
    "\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: 카메라 열기 실패\")\n",
    "        exit()\n",
    "\n",
    "    # info\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc_val = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    codec = \"\".join([chr((fourcc_val >> 8 * i) & 0xFF) for i in range(4)])\n",
    "\n",
    "    print(f\"{width} x {height} {codec}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame_np = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Error: 프레임이 없습니다\")\n",
    "                break\n",
    "\n",
    "            # h, w, c\n",
    "            h, w, c = frame_np.shape\n",
    "            half_w = w//2\n",
    "\n",
    "            l_frame = frame_np[:, :half_w]\n",
    "            # r_frame = frame[:, half_w:]\n",
    "\n",
    "            # 추론\n",
    "            keypoints = inference(model, l_frame, DEVICE)\n",
    "\n",
    "            # 시각화\n",
    "            keypoint = keypoints.cpu().numpy()\n",
    "\n",
    "            if keypoint.ndim == 3:\n",
    "                keypoint = keypoint[0]\n",
    "\n",
    "            for pt in keypoint:\n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                \n",
    "                if 0 <= x < half_w and 0 <= y < h:\n",
    "                    # cv2.circle(img, (x, y), 반지름, 색상, 두께)\n",
    "                    cv2.circle(l_frame, (x, y), 5, (0, 255, 0), -1) # 녹색\n",
    "\n",
    "            l_frame = cv2.resize(l_frame, (640, 480))\n",
    "            cv2.imshow(\"infer\", l_frame)\n",
    "\n",
    "            if cv2.waitKey(1) == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
